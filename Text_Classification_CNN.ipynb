{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080d50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator \n",
    "from torchtext.datasets import DATASETS\n",
    "from torchtext.vocab import build_vocab_from_iterator, FastText\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329c056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_DATASET = \"AG_NEWS\"\n",
    "DATASET_DIR = \"data\"\n",
    "DEVICE_TYPE = \"cpu\"\n",
    "EMBEDDING_DIM = 300\n",
    "LEARNING_RATE = 4.0\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "PAD_VALUE = 0\n",
    "PAD_IDX = PAD_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e3b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4a0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48f23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = DATASETS[SELECTED_DATASET](root=DATASET_DIR, split=\"train\")\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data_iter), specials=('<pad>', '<unk>'))\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10392556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/wiki.simple.vec: 293MB [00:04, 63.2MB/s]                              \n",
      "  0%|          | 0/111051 [00:00<?, ?it/s]Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████| 111051/111051 [00:09<00:00, 11549.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get Embeddings\n",
    "FAST_TEXT = FastText(\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16ca1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(text):\n",
    "    return vocab(tokenizer(text))\n",
    "\n",
    "def label_pipeline(label):\n",
    "    return int(label) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff479986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels, texts = [], []\n",
    "    for (label, text) in batch:\n",
    "        labels.append(label_pipeline(label))\n",
    "        processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
    "        texts.append(processed_text.clone().detach())\n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.int64)\n",
    "    texts = pad_sequence(texts, batch_first=True)\n",
    "            \n",
    "    return labels.to(DEVICE_TYPE), texts.to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e617ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DATASETS[SELECTED_DATASET](root=DATASET_DIR, split=\"train\")\n",
    "num_classes = len(set([label for (label, _) in train_iter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc51c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "\n",
    "class CNN1dClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes, embed_dim=300, pretrained=True, fine_tune=True):\n",
    "        super(CNN1dClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            for i in range(vocab_size):\n",
    "                token = vocab.lookup_token(i)\n",
    "                                \n",
    "                self.embedding.weight[i, :] = FAST_TEXT.get_vecs_by_tokens(\n",
    "                    token, \n",
    "                    lower_case_backup=True\n",
    "                )\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        else:\n",
    "            self.init_weights()\n",
    "                \n",
    "        if not fine_tune:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(embed_dim, 1, 2)\n",
    "        self.conv3 = nn.Conv1d(embed_dim, 1, 3)\n",
    "        self.conv4 = nn.Conv1d(embed_dim, 1, 4)\n",
    "        \n",
    "        self.fc = nn.Linear(3, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.debug = True\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        if self.debug:\n",
    "            print('embedding', embedded.shape)\n",
    "        \n",
    "        embedded = embedded.transpose(1, 2)\n",
    "        \n",
    "        conv2_out = nn.ReLU()(self.conv2(embedded))\n",
    "        if self.debug:\n",
    "            print('conv2', conv2_out.shape)\n",
    "        \n",
    "        conv3_out = nn.ReLU()(self.conv3(embedded))\n",
    "        if self.debug:\n",
    "            print('conv3', conv3_out.shape)\n",
    "        \n",
    "        conv4_out = nn.ReLU()(self.conv4(embedded))\n",
    "        if self.debug:\n",
    "            print('conv4', conv4_out.shape)\n",
    "        \n",
    "        conv2_out = nn.MaxPool1d(conv2_out.size(-1))(conv2_out)\n",
    "        conv3_out = nn.MaxPool1d(conv3_out.size(-1))(conv3_out)\n",
    "        conv4_out = nn.MaxPool1d(conv4_out.size(-1))(conv4_out)\n",
    "        if self.debug:\n",
    "            print('conv2 after max', conv2_out.shape)\n",
    "        \n",
    "        conv_concat = self.dropout(\n",
    "            torch.cat((conv2_out.squeeze(1), conv3_out.squeeze(1), conv4_out.squeeze(1)), -1)\n",
    "        )\n",
    "        if self.debug:\n",
    "            print('conv concat', conv_concat.shape)\n",
    "                        \n",
    "        out = self.fc(conv_concat)\n",
    "        \n",
    "        self.debug = False\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class CNN2dClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes, embed_dim=300, pretrained=True, fine_tune=True):\n",
    "        super(CNN2dClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            for i in range(vocab_size):\n",
    "                tokens = vocab.lookup_token(i)\n",
    "                self.embedding.weight[i, :] = FAST_TEXT.get_vecs_by_tokens(tokenizer(tokens), lower_case_backup=True)\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        else:\n",
    "            self.init_weights()\n",
    "                \n",
    "        if not fine_tune:\n",
    "            self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        self.convs = [\n",
    "            nn.Conv2d(1, 1, (embed_dim, 2)),\n",
    "            nn.Conv2d(1, 1, (embed_dim, 3)),\n",
    "            nn.Conv2d(1, 1, (embed_dim, 4))\n",
    "        ]\n",
    "        \n",
    "        self.fc = nn.Linear(3, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.debug = True\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        if self.debug:\n",
    "            print('embedded ', embedded.shape)\n",
    "        \n",
    "        embedded = embedded.transpose(1, 2)\n",
    "        \n",
    "        if self.debug:\n",
    "            print('embedded ', embedded.shape)\n",
    "                    \n",
    "        convs = [\n",
    "            nn.ReLU()(conv(embedded.unsqueeze(1))) for conv in self.convs\n",
    "        ]\n",
    "        \n",
    "        if self.debug:\n",
    "            print('conv ', [c.shape for c in convs])\n",
    "        \n",
    "        pooled = [\n",
    "            nn.MaxPool2d((1, conv.size(-1)))(conv).squeeze() for conv in convs\n",
    "        ]\n",
    "        \n",
    "        if self.debug:\n",
    "            print('pooled ', [c.shape for c in pooled])\n",
    "        \n",
    "        pooled_stack = self.dropout(torch.vstack(pooled).t())\n",
    "        \n",
    "        if self.debug:\n",
    "            print('pooled_stack ', pooled_stack.shape)\n",
    "            \n",
    "                        \n",
    "        out = self.fc(pooled_stack)\n",
    "        \n",
    "        self.debug = False\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c6ed5",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef585f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE_TYPE)\n",
    "model_1d = CNN1dClassifier(len(vocab), num_classes).to(DEVICE_TYPE)\n",
    "model_2d = CNN2dClassifier(len(vocab), num_classes).to(DEVICE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7f681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_1d\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c0aebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = DATASETS[SELECTED_DATASET]()\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train, split_valid = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24950481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 1000\n",
    "\n",
    "    for idx, (label, text) in tqdm(enumerate(dataloader), total=len(dataloader), mininterval=3):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text)\n",
    "                \n",
    "        loss = criterion(input=predicted_label, target=label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(epoch, idx, len(dataloader), total_acc / total_count)\n",
    "            )\n",
    "            total_acc, total_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39a702be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e02c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding torch.Size([16, 66, 300])\n",
      "conv2 torch.Size([16, 1, 65])\n",
      "conv3 torch.Size([16, 1, 64])\n",
      "conv4 torch.Size([16, 1, 63])\n",
      "conv2 after max torch.Size([16, 1, 1])\n",
      "conv concat torch.Size([16, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 926/7125 [00:21<02:19, 44.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/ 7125 batches | accuracy    0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1930/7125 [00:42<01:48, 47.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2000/ 7125 batches | accuracy    0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 2954/7125 [01:03<01:26, 48.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  3000/ 7125 batches | accuracy    0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 4001/7125 [01:25<01:03, 49.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  4000/ 7125 batches | accuracy    0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 4984/7125 [01:47<00:49, 43.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5000/ 7125 batches | accuracy    0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 5954/7125 [02:11<00:27, 43.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  6000/ 7125 batches | accuracy    0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6923/7125 [02:38<00:05, 36.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  7000/ 7125 batches | accuracy    0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7125/7125 [02:43<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 164.90s | valid accuracy    0.741 \n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1006/7125 [00:32<03:14, 31.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  1000/ 7125 batches | accuracy    0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1917/7125 [01:04<02:49, 30.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  2000/ 7125 batches | accuracy    0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 2951/7125 [01:39<02:17, 30.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  3000/ 7125 batches | accuracy    0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3975/7125 [02:15<01:42, 30.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  4000/ 7125 batches | accuracy    0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 4959/7125 [02:44<01:08, 31.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  5000/ 7125 batches | accuracy    0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 5967/7125 [03:16<00:33, 34.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  6000/ 7125 batches | accuracy    0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 6963/7125 [03:44<00:04, 35.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  7000/ 7125 batches | accuracy    0.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7125/7125 [03:49<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 231.30s | valid accuracy    0.802 \n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 937/7125 [00:27<02:56, 35.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  1000/ 7125 batches | accuracy    0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1980/7125 [00:56<02:22, 36.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  2000/ 7125 batches | accuracy    0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2988/7125 [01:27<02:27, 27.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  3000/ 7125 batches | accuracy    0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3998/7125 [01:55<01:25, 36.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  4000/ 7125 batches | accuracy    0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 4900/7125 [02:20<01:02, 35.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  5000/ 7125 batches | accuracy    0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5908/7125 [02:48<00:32, 37.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  6000/ 7125 batches | accuracy    0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 6991/7125 [03:16<00:03, 37.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  7000/ 7125 batches | accuracy    0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7125/7125 [03:19<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 201.31s | valid accuracy    0.809 \n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 946/7125 [00:27<02:46, 37.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  1000/ 7125 batches | accuracy    0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1954/7125 [00:55<02:23, 36.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  2000/ 7125 batches | accuracy    0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2930/7125 [01:23<02:05, 33.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  3000/ 7125 batches | accuracy    0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3931/7125 [01:52<01:34, 33.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  4000/ 7125 batches | accuracy    0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 4884/7125 [02:17<01:03, 35.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  5000/ 7125 batches | accuracy    0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 5963/7125 [02:47<00:31, 37.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  6000/ 7125 batches | accuracy    0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6881/7125 [03:15<00:08, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  7000/ 7125 batches | accuracy    0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7125/7125 [03:21<00:00, 35.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 203.34s | valid accuracy    0.808 \n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 969/7125 [00:28<02:57, 34.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  1000/ 7125 batches | accuracy    0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1953/7125 [00:55<02:41, 32.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  2000/ 7125 batches | accuracy    0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2980/7125 [01:23<01:54, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  3000/ 7125 batches | accuracy    0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3949/7125 [01:51<01:27, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  4000/ 7125 batches | accuracy    0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 4956/7125 [02:21<01:09, 31.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  5000/ 7125 batches | accuracy    0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 6001/7125 [02:53<00:35, 31.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  6000/ 7125 batches | accuracy    0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6911/7125 [03:21<00:06, 32.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  7000/ 7125 batches | accuracy    0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7125/7125 [03:27<00:00, 34.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 209.52s | valid accuracy    0.809 \n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test accuracy    0.812\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, model, optimizer, criterion, epoch)\n",
    "    accu_val = evaluate(valid_dataloader, model)\n",
    "    scheduler.step()\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
    "        \"valid accuracy {:8.3f} \".format(epoch, time.time() - epoch_start_time, accu_val)\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "print(\"Checking the results of test dataset.\")\n",
    "accu_test = evaluate(test_dataloader, model)\n",
    "print(\"test accuracy {:8.3f}\".format(accu_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
