{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080d50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.datasets import DATASETS\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from torch import FloatTensor as FT\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b412ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "window_size = 1\n",
    "negative_samples = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32bf008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95M\tdata/text8\n"
     ]
    }
   ],
   "source": [
    "#The text8 Wikipedia corpus. 100M characters.\n",
    "!du -h data/text8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3217b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/text8', 'r') as f:\n",
    "    corpus = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1bf892",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_\\'{|}~\\t\\n'\n",
    "for c in punc:\n",
    "    if c in corpus:\n",
    "        corpus.replace(c, ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc19b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(corpus)\n",
    "token_counts = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16b736a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out low-frequency tokens\n",
    "filtered_tokens = [token for token in tokens if token_counts[token] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ad817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator([filtered_tokens])\n",
    "# word -> int hash map.\n",
    "token_to_idx = vocab.get_stoi()\n",
    "# int -> word hash map.\n",
    "idx_to_token = vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e543e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative sampling\n",
    "threshold = 1e-5\n",
    "token_probs = {token: (np.sqrt(token_counts[token] / 0.001) + 1) * (0.0001 / token_counts[token]) for token in token_counts}\n",
    "\n",
    "train_tokens = [token for token in filtered_tokens if random.random() < token_probs[token]]\n",
    "train_vocab = build_vocab_from_iterator([train_tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d202b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token_to_idx = vocab.get_stoi()\n",
    "train_idx_to_token = vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9346f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq = Counter(train_tokens)\n",
    "token_probs = torch.zeros(len(train_vocab))\n",
    "\n",
    "s = sum([np.power(freq, 0.75) for token, freq in token_freq.items()])\n",
    "for token in token_freq:\n",
    "    token_probs[train_token_to_idx[token]] = np.power(token_freq[token], 0.75) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c83174",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token_ids = [train_token_to_idx[token] for token in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e96c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just gets the (wc, wo) pairs that are positive, which means they are seen together\n",
    "def create_cbow_dataset(token_ids, window_size):\n",
    "    context_target_pairs = []\n",
    "    for i, token_id in enumerate(token_ids):\n",
    "        context_start = max(0, i - window_size)\n",
    "        context_end = min(i + window_size, len(token_ids) - 1)\n",
    "        left_context = token_ids[context_start:i]\n",
    "        right_context = token_ids[i+1:context_end+1]\n",
    "\n",
    "        if len(left_context) == len(right_context):\n",
    "            context = left_context + right_context\n",
    "            target = token_id\n",
    "            context_target_pairs.append(context + [target])\n",
    "\n",
    "    return context_target_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eb82aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_cbow_dataset(train_token_ids, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e31ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the dataloader.\n",
    "train_dataloader = DataLoader(\n",
    "    TensorDataset(torch.tensor(train_dataset).to(device)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffada8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_token_ids = torch.tensor([\n",
    "    train_token_to_idx['money'],\n",
    "    train_token_to_idx['lion'],\n",
    "    train_token_to_idx['africa'],\n",
    "    train_token_to_idx['musician'],\n",
    "    train_token_to_idx['dance'],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc51c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model.\n",
    "\n",
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOWModel, self).__init__()\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.context_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.target_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, context_ids):\n",
    "        context_embeds = self.context_embeddings(context_ids[:, :-1])\n",
    "        context_embeds_mean = context_embeds.mean(axis=1)\n",
    "\n",
    "        target_embeds = self.target_embeddings(context_ids[:, -1])\n",
    "\n",
    "        logits = (context_embeds_mean * target_embeds).sum(axis=-1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed9c509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_model(model, validation_ids, idx_to_token):\n",
    "    embedding_weights = model.context_embeddings.weight\n",
    "\n",
    "    normalized_embeddings = embedding_weights.cpu() / np.sqrt(np.sum(embedding_weights.cpu().numpy()**2, axis=1, keepdims=True))\n",
    "\n",
    "    validation_embeddings = normalized_embeddings[validation_ids, :]\n",
    "\n",
    "    top_k = 10\n",
    "    similarity = np.dot(validation_embeddings.cpu().numpy(), normalized_embeddings.cpu().numpy().T)\n",
    "    similarity_top_k = np.argsort(-similarity, axis=1)[:, 1: top_k+1]\n",
    "\n",
    "    for i, token_id in enumerate(validation_ids):\n",
    "        similar_tokens = ', '.join([idx_to_token[j] for j in similarity_top_k[i, :] if j >= 1])\n",
    "        print(f\"{idx_to_token[token_id]}: {similar_tokens}\")\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16da95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "\n",
    "learning_rate = 10.0\n",
    "num_epochs = 10\n",
    "embedding_dim = 300\n",
    "\n",
    "model = CBOWModel(len(vocab), embedding_dim).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a642bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOWModel(\n",
       "  (context_embeddings): Embedding(63641, 300)\n",
       "  (target_embeddings): Embedding(63641, 300)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24950481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_batches = 0.0, 0.0\n",
    "    log_interval = 500\n",
    "\n",
    "    for idx, (context_ids,) in tqdm(enumerate(dataloader)):\n",
    "        batch_size = context_ids.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(context_ids)\n",
    "\n",
    "        positive_loss = torch.nn.BCEWithLogitsLoss()(input=logits, target=torch.ones(batch_size).to(device).float())\n",
    "\n",
    "        negative_samples_ids = torch.multinomial(token_probs, batch_size * negative_samples, replacement=True)\n",
    "\n",
    "        context_ids_repeated = torch.concat([c.repeat(negative_samples, 1) for c in torch.tensor(context_ids[:, :-1]).split(1)])\n",
    "        negative_target_ids = negative_samples_ids.unsqueeze(-1)\n",
    "\n",
    "        negative_context_ids = torch.concat([context_ids_repeated, negative_target_ids.to(device)], axis=1)\n",
    "\n",
    "        negative_loss = model(negative_context_ids).neg().sigmoid().log().reshape(batch_size, negative_samples).sum(1).mean().neg().to(device)\n",
    "\n",
    "        loss = (positive_loss + negative_loss).mean()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            param_ratios = [(learning_rate * p.grad.std() / p.data.std()).log10().item() for _, p in model.named_parameters()]\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "\n",
    "        if idx % log_interval == 0:\n",
    "            print(f\"| epoch {epoch:3d} | {idx:5d}/{len(dataloader):5d} batches | loss {total_loss / total_batches:8.3f}\")\n",
    "            validate_model(model, validation_token_ids, train_idx_to_token)\n",
    "            total_loss, total_batches = 0.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9e02c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/mx/41vmmjnx00z2pm2st2dnvjb40000gn/T/ipykernel_70084/116710006.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  context_ids_repeated = torch.concat([c.repeat(negative_samples, 1) for c in torch.tensor(context_ids[:, :-1]).split(1)])\n",
      "1it [00:02,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     0/32580 batches | loss    4.088\n",
      "money: biplanes, attaches, giri, wigner, prepositional, paracetamol, mich, uwb, fanbase, gin\n",
      "lion: maya, dare, buonarroti, practises, younger, risked, rhineland, ramzi, bains, cortina\n",
      "africa: shapiro, batsmen, forgetful, extravagance, nicephorus, clis, comedic, micronesia, aspen, phthalocyanine\n",
      "musician: northland, sentience, protectionism, mondegreen, gera, dsa, myrrh, determine, encyclop, ungodly\n",
      "dance: banshees, exceeds, wtoo, endomorphisms, samoans, screename, appreciable, huygens, gorges, reunited\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [01:21,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/32580 batches | loss    2.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [01:21,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "money: biplanes, giri, wigner, attaches, prepositional, paracetamol, sensuous, fanbase, mich, gin\n",
      "lion: maya, dare, buonarroti, practises, younger, risked, rhineland, ramzi, cortina\n",
      "africa: forgetful, extravagance, batsmen, shapiro, nicephorus, comedic, clis, aspen, micronesia, molality\n",
      "musician: northland, protectionism, sentience, mondegreen, gera, myrrh, determine, dsa, neuroanatomy, ungodly\n",
      "dance: banshees, wtoo, samoans, exceeds, screename, endomorphisms, appreciable, huygens, kantele, gorges\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [02:35,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1000/32580 batches | loss    2.021\n",
      "money: biplanes, all, wigner, giri, they, sensuous, fanbase, mobile, is, prepositional\n",
      "lion: maya, buonarroti, dare, practises, younger, risked, rhineland, ramzi, cortina, buffett\n",
      "africa: forgetful, extravagance, batsmen, comedic, shapiro, alai, aspen, kilowatt, bum, clis\n",
      "musician: northland, protectionism, sentience, mondegreen, myrrh, neuroanatomy, gera, determine, orloff, drunkenness\n",
      "dance: banshees, wtoo, samoans, exceeds, appreciable, screename, kantele, reunited, endomorphisms, huygens\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [03:48,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  1500/32580 batches | loss    1.790\n",
      "money: all, so, biplanes, they, such, mobile, wigner, high, giri, sensuous\n",
      "lion: maya, dare, buonarroti, practises, younger, risked, rhineland, ramzi, states, cortina\n",
      "africa: forgetful, extravagance, batsmen, since, free, comedic, years, death, close, due\n",
      "musician: northland, protectionism, sentience, determine, mondegreen, myrrh, neuroanatomy, gera, management, orloff\n",
      "dance: wtoo, samoans, banshees, appreciable, exceeds, kantele, european, reunited, art, special\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [05:03,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2000/32580 batches | loss    1.642\n",
      "money: all, so, high, mobile, case, biplanes, amount, they, such, is\n",
      "lion: maya, dare, buonarroti, younger, practises, states, day, risked, rhineland\n",
      "africa: since, free, extravagance, forgetful, death, due, years, batsmen, greek, other\n",
      "musician: northland, protectionism, art, determine, management, sentience, mondegreen, changed, cost, neuroanatomy\n",
      "dance: wtoo, samoans, european, banshees, art, special, exceeds, appreciable, kantele, higher\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [06:24,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  2500/32580 batches | loss    1.543\n",
      "money: all, so, mobile, high, amount, case, list, him, more, wars\n",
      "lion: maya, younger, dare, buonarroti, practises, day, practice, states, well, lives\n",
      "africa: free, death, forgetful, extravagance, due, since, greek, batsmen, went, years\n",
      "musician: art, northland, determine, management, protectionism, cost, changed, near, oxford, book\n",
      "dance: european, wtoo, art, samoans, banshees, special, higher, exceeds, kantele, appreciable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [07:42,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  3000/32580 batches | loss    1.474\n",
      "money: amount, mobile, so, wars, all, case, is, sea, high, more\n",
      "lion: maya, younger, dare, buonarroti, day, practice, well, practises, states, lives\n",
      "africa: death, free, forgetful, extravagance, due, greek, went, since, batsmen, both\n",
      "musician: art, determine, management, northland, changed, cost, protectionism, book, near, de\n",
      "dance: art, european, wtoo, samoans, special, higher, banshees, particularly, kantele, exceeds\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3500it [09:02,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  3500/32580 batches | loss    1.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3502it [09:02,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "money: amount, wars, mobile, all, case, sea, so, function, more, end\n",
      "lion: maya, younger, dare, practice, buonarroti, well, states, day, lives, practises\n",
      "africa: death, went, free, extravagance, due, forgetful, greek, batsmen, top, march\n",
      "musician: art, determine, management, changed, book, cost, northland, allowed, near, de\n",
      "dance: art, european, wtoo, special, higher, samoans, particularly, kantele, enemy, banshees\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [10:22,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  4000/32580 batches | loss    1.373\n",
      "money: amount, wars, mobile, case, function, so, end, all, sea, italian\n",
      "lion: maya, younger, practice, dare, buonarroti, lives, well, day, practises, states\n",
      "africa: death, went, extravagance, free, forgetful, top, due, greek, march, batsmen\n",
      "musician: art, changed, management, determine, cost, book, allowed, de, near, northland\n",
      "dance: art, european, wtoo, special, samoans, higher, particularly, enemy, kantele, field\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [11:41,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  4500/32580 batches | loss    1.337\n",
      "money: amount, wars, mobile, sea, case, end, so, more, candidate, attention\n",
      "lion: maya, younger, practice, dare, buonarroti, lives, well, states, in, day\n",
      "africa: death, went, extravagance, forgetful, top, due, america, greek, clinton, batsmen\n",
      "musician: art, changed, determine, management, allowed, cost, de, book, near, school\n",
      "dance: art, european, higher, special, wtoo, particularly, samoans, enemy, court, religion\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [12:59,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5000/32580 batches | loss    1.305\n",
      "money: wars, amount, mobile, sea, end, more, candidate, attention, case, function\n",
      "lion: younger, maya, practice, dare, buonarroti, lives, day, in, states, island\n",
      "africa: death, went, america, forgetful, coast, top, extravagance, clinton, greek, needed\n",
      "musician: art, changed, determine, cost, management, allowed, de, school, book, oxford\n",
      "dance: art, european, higher, samoans, wtoo, special, particularly, enemy, kantele, religion\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [14:17,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  5500/32580 batches | loss    1.276\n",
      "money: wars, amount, mobile, candidate, function, attention, sea, so, case, jack\n",
      "lion: younger, maya, practice, dare, lives, buonarroti, day, speech, practises, island\n",
      "africa: america, death, went, coast, top, extravagance, clinton, forgetful, needed, greek\n",
      "musician: art, cost, changed, management, determine, allowed, de, book, school, near\n",
      "dance: art, european, samoans, higher, special, wtoo, enemy, particularly, foundation, kantele\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [15:34,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  6000/32580 batches | loss    1.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [15:35,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "money: amount, wars, mobile, attention, function, candidate, case, jack, sea, difficult\n",
      "lion: younger, maya, practice, dare, lives, buonarroti, day, speech, practises, states\n",
      "africa: america, death, coast, went, extravagance, clinton, forgetful, needed, top, batsmen\n",
      "musician: art, changed, cost, management, determine, allowed, de, book, oxford, school\n",
      "dance: art, european, samoans, enemy, wtoo, higher, special, foundation, kantele, particularly\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [16:51,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  6500/32580 batches | loss    1.233\n",
      "money: amount, wars, mobile, candidate, attention, function, jack, case, more, divided\n",
      "lion: maya, younger, practice, dare, lives, buonarroti, day, states, speech, practises\n",
      "africa: america, coast, death, went, extravagance, clinton, needed, forgetful, march, prepared\n",
      "musician: art, cost, changed, determine, management, allowed, de, oxford, book, choose\n",
      "dance: art, european, samoans, wtoo, higher, foundation, enemy, particularly, special, kantele\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7000it [18:06,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  7000/32580 batches | loss    1.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7002it [18:06,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "money: amount, wars, mobile, attention, candidate, maintains, function, case, jack, divided\n",
      "lion: younger, maya, practice, dare, lives, buonarroti, day, speech, states, dead\n",
      "africa: america, coast, death, extravagance, went, clinton, plato, prepared, needed, forgetful\n",
      "musician: art, cost, changed, management, determine, de, oxford, actress, allowed, northland\n",
      "dance: art, european, higher, samoans, wtoo, foundation, enemy, particularly, renamed, mean\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7335it [19:00,  6.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, optimizer, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m positive_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlogits, target\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     15\u001b[0m negative_samples_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(token_probs, batch_size \u001b[38;5;241m*\u001b[39m negative_samples, replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m context_ids_repeated \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([c\u001b[38;5;241m.\u001b[39mrepeat(negative_samples, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(context_ids[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m     18\u001b[0m negative_target_ids \u001b[38;5;241m=\u001b[39m negative_samples_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m negative_context_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([context_ids_repeated, negative_target_ids\u001b[38;5;241m.\u001b[39mto(device)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m positive_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlogits, target\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     15\u001b[0m negative_samples_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(token_probs, batch_size \u001b[38;5;241m*\u001b[39m negative_samples, replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m context_ids_repeated \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(context_ids[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m1\u001b[39m)])\n\u001b[1;32m     18\u001b[0m negative_target_ids \u001b[38;5;241m=\u001b[39m negative_samples_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m negative_context_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([context_ids_repeated, negative_target_ids\u001b[38;5;241m.\u001b[39mto(device)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_epoch(train_dataloader, model, optimizer, epoch)\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
